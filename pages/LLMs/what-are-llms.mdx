# What are Large Language Models?

Large Language Models (LLMs) are artificial intelligence (AI) systems that are trained on massive amounts of text data to perform a wide range of natural language processing (NLP) tasks. They are designed to generate human-like text and can be used for a variety of applications, including language translation, text summarization, and question-answering.

Large language models are normally based on very large, deep neural networks.

In this module, youâ€™ll be learning the architecture of large language models.

To start we will discuss embeddings, which are representations of words and phrases in a high-dimensional space, and how they can be used to measure similarity between different pieces of text.

We will also explore attention, which is a mechanism that allows models to focus on specific parts of the input during processing. We will examine the transformer model architecture, which is the backbone of many state-of-the-art language models, and how it has revolutionized the field of NLP.

Throughout this module, we will use practical examples and hands-on exercises to ensure that you have a comprehensive understanding of these topics and are able to apply them in real-world scenarios.